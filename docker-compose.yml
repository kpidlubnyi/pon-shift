services:
  core:
    build:
      context: .
      dockerfile: ./core/Dockerfile
    container_name: core
    volumes:
      - ./core:/app
      - static_volume:/app/static
      - logs_volume:/app/logs
      - ./otp:/otp
    ports:
      - "8001:8000"
    networks:
      - core-network
    depends_on:
      postgres-db:
        condition: service_healthy
      redis:
        condition: service_healthy
      mongo-db:
        condition: service_healthy
      ors:
        condition: service_healthy
    env_file:
      - .env
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8000/health/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 8m
    restart: unless-stopped

  postgres-db:
    image: postgres:16
    container_name: postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    env_file:
      - .env
    ports:
      - "5433:5432"
    networks:
      - core-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h ${DB_HOST} -U ${DB_USER} -d ${DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5

  mongo-db:
    image: mongo:8
    container_name: mongo
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_DB_NAME}
    env_file:
      - .env
    volumes:
      - mongo_data:/data/db
    networks:
      - core-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7.2-alpine
    container_name: redis
    volumes:
      - redis_data:/data
    networks:
      - core-network
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  celery-worker-default:
    build:
      context: .
      dockerfile: ./core/Dockerfile
    container_name: celery-worker-default
    command: celery -A core worker -Q default --loglevel=info --concurrency=4 -n default@%h
    volumes:
      - ./core:/app
      - logs_volume:/app/logs
    depends_on:
      core:
        condition: service_healthy
      postgres-db:
        condition: service_healthy
      mongo-db:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - .env
    networks:
      - core-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "celery -A core inspect ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  celery-worker-gtfs:
    build:
      context: .
      dockerfile: ./core/Dockerfile
    container_name: celery-worker-gtfs
    command: celery -A core worker -Q gtfs_updates --loglevel=info --concurrency=1 -n gtfs@%h
    volumes:
      - ./core:/app
      - logs_volume:/app/logs
    depends_on:
      core:
        condition: service_healthy
      postgres-db:
        condition: service_healthy
      mongo-db:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - .env
    networks:
      - core-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "celery -A core inspect ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  celery-beat:
    build:
      context: .
      dockerfile: ./core/Dockerfile
    container_name: celery-beat
    command: celery -A core beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    volumes:
      - ./core:/app
      - logs_volume:/app/logs
    depends_on:
      celery-worker-default:
        condition: service_healthy
      celery-worker-gtfs:
        condition: service_healthy
      postgres-db:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - .env
    networks:
      - core-network
    restart: unless-stopped

  ors:
    build:
      context: ./ors
    container_name: ors
    volumes:
      - ./ors/graphs:/home/ors/graphs
      - ./ors/logs:/home/ors/logs
      - ./ors/elevation_cache:/home/ors/elevation_cache
      - ./ors/files:/home/ors/files
      - ./ors/conf:/home/ors/config
    environment:
      REBUILD_GRAPHS: "True"
      CONTAINER_LOG_LEVEL: "INFO"
      XMS: 3g
      XMX: 4g
    networks:
      - core-network
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8082/ors/v2/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 5m
    restart: unless-stopped

  otp:
    build: 
      context: ./otp
    container_name: otp
    environment:
      - JAVA_OPTS=-Xmx5G -Xms1G
    networks:
      - core-network
    command: "--load --serve"
    ports:
      - "8081:8080"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/actuators/health"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 7m

volumes:
  postgres_data:
    driver: local
  mongo_data:
    driver: local
  redis_data:
    driver: local
  static_volume:
    driver: local
  logs_volume:
    driver: local

networks:
  core-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16